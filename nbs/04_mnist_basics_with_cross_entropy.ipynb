{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using cross entropy loss for the MNIST_SAMPLE dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:** As in the last notebook, I want to move towards classifying the full MNIST dataset of ten digits by first working with loss functions that can work with N activations from the final layer for the smaller MNIST_SAMPLE dataset. The MNIST_SAMPLE dataset has data only for two digits (3s and 7s). The loss functions I explored previously were the `mnist_loss`, `softmax_loss`, and `cross_entropy_loss`. However, at that time, I had been unable to successfully use `cross_entropy_loss` for this dataset and assumed that we could use `softmax_loss` instead as it seemed to work well.\n",
    "\n",
    "Turns out that I was defining the `batch_accuracy` function incorrectly then. I learnt this the hard way when I tried scaling up from two to ten categories. The `softmax_loss` function was just not able to push the accuracy up. After some head-scratching and googling, I realized the book did not teach us precisely how to calculate the `batch_accuracy` for the case where the last layer has N activations corresponding to N categories. Fortunately, it is not that hard and I found a good reference [here](https://jonathan-sands.com/deep%20learning/fastai/pytorch/vision/classifier/2020/11/15/MNIST.html#Training-a-neural-network). The key looks to be to use the [`torch.max`](https://pytorch.org/docs/stable/generated/torch.max.html) function to select the column index with the maximum activation value and compare that to `y` (the dependent variable).\n",
    "\n",
    "As before, the reference for everything in this blog post is the [fastai 2020 course](https://course.fast.ai), especially the [amazing textbook](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527).\n",
    "\n",
    "In this notebook, I learn how to use the `cross_entropy_loss` for the MNIST_SAMPLE dataset with two categories. Scaling up to ten categories from this point should be straight-forward from here and is the topic of my next notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the basic imports out of the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get your data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [Path('/home/igolgi/.fastai/data/mnist_sample/valid'),Path('/home/igolgi/.fastai/data/mnist_sample/labels.csv'),Path('/home/igolgi/.fastai/data/mnist_sample/train'),Path('/home/igolgi/.fastai/data/mnist_sample/models')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 28, 28]), torch.Size([6265, 28, 28]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_imgs = (path/'train'/'3').ls().sorted()\n",
    "seven_imgs = (path/'train'/'7').ls().sorted()\n",
    "\n",
    "three_tensors_list = [tensor(Image.open(img)) for img in three_imgs]\n",
    "seven_tensors_list = [tensor(Image.open(img)) for img in seven_imgs]\n",
    "\n",
    "stacked_threes = torch.stack(three_tensors_list).float()/255.\n",
    "stacked_sevens = torch.stack(seven_tensors_list).float()/255.\n",
    "stacked_threes.shape, stacked_sevens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(three_tensors_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(seven_tensors_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]); train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in the training data, there are a total of 12396 images of 28x28 pixels for the 3s and 7s. Lets \"flatten\" the 28x28 matrix into one long row of 784 pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train_x.view(-1, 28*28); train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now, we have 12396 rows of 784 pixel values per image as part of the training dataset. Let us create the labels for each of these images so that a label of 1 corresponds to 3s and a label of 0 corresponds to a 7. This is the same as with the `mnist_loss` function in the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = tensor( [1]*len(three_imgs) + [0]*len(seven_imgs) ).unsqueeze(1); train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we perform the same set of actions for the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_three_imgs = (path/'valid'/'3').ls().sorted()\n",
    "valid_seven_imgs = (path/'valid'/'7').ls().sorted()\n",
    "\n",
    "valid_three_tensors_list = [tensor(Image.open(img)) for img in valid_three_imgs]\n",
    "valid_seven_tensors_list = [tensor(Image.open(img)) for img in valid_seven_imgs]\n",
    "\n",
    "valid_stacked_threes = torch.stack(valid_three_tensors_list).float()/255.\n",
    "valid_stacked_sevens = torch.stack(valid_seven_tensors_list).float()/255.\n",
    "valid_stacked_threes.shape, valid_stacked_sevens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's flatten the validation dataset (28x28 images) into rows of 784 pixels. And let's create labels the same way we did for the training data, i.e. 1 to represent 3s and 0 to represent 7s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2038, 784])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x = torch.cat([valid_stacked_threes, valid_stacked_sevens]).view(-1, 28*28); valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2038, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y = tensor( [1]*len(valid_three_imgs) + [0]*len(valid_seven_imgs) ).unsqueeze(1); valid_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(train_x, train_y))\n",
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)\n",
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a basic linear classifier going as well as the loss functions, optimizers and metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear1(xb, weights, bias): return xb@weights + bias # linear classifier with one weight per pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(preds, tgts):\n",
    "    preds = preds.sigmoid()\n",
    "    return torch.where(tgts==1, 1-preds, preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(preds, tgts):\n",
    "    preds = torch.log_softmax(preds, dim=1)\n",
    "    #print(preds.shape, preds[0], preds[:,0].shape[0])\n",
    "    return F.nll_loss(preds, torch.squeeze(tgts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad_mnist_loss(xb, yb, model, params):\n",
    "    preds = model(xb, params[0], params[1])\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad_ce_loss(xb, yb, model, params):\n",
    "    preds = model(xb, params[0], params[1])\n",
    "    loss = cross_entropy_loss(preds, yb)\n",
    "    #print(loss)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_weights(params, lr):\n",
    "    for p in params:\n",
    "        p.data -= p.grad*lr\n",
    "        p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params, calc_grad_func):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad_func(xb,yb,model,params)\n",
    "        step_weights(params,lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we define the batch_accuracy function? Let us look at a small batch and work it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us work with 4 of the input images in the first batch. We want to walk through the process of looking at the images (x), the labels (y), the weights and biases in the linear model function/classifier we use, and the predictions returned by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dl.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 2]), torch.Size([2]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = init_params((28*28,2)); b = init_params(2); w.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 784]), torch.Size([4, 2]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:4].shape, w[:4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts = linear1(x[:4], w, b); acts[:,0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.7714,  -4.5953],\n",
       "        [-13.9319,   0.0812],\n",
       "        [ -2.5972,  -5.2215],\n",
       "        [-17.7803,  10.3004]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the activations from the linear model\n",
    "\n",
    "`acts` is the activations from the \"final\" layer in our model here. Note that there are two columns  of activations. So, what meaning can we assign to these two columns and to the two values in each row? \n",
    "\n",
    "Well, each column corresponds to the activation score for each category. And **in each row, we should pick the index corresponding to the maximum value as the category that is predicted**. This matches what the textbook says about how to interpret multi-column activations.\n",
    "\n",
    "So, for example, in the `acts` tensor above,\n",
    "- in row 0, the maximum value is -4.5953 and this corresponds to index 1. This means the predicted value is 1\n",
    "- in row 1, the maximum value is 0.0812 and this corresponds to index 1. This means the predicted value is 1\n",
    "- and so on\n",
    "\n",
    "The final prediction here should be [1,1,0,1]. This prediction can then be compared against the `y` to calculate the batch_accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, the `torch.max` function can return a tuple with the maximum value in each row as well as the index location of this maximum value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-4.5953,  0.0812, -2.5972, 10.3004], grad_fn=<MaxBackward0>),\n",
       " tensor([1, 1, 0, 1]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_acts,preds = torch.max(acts, 1); max_acts, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is then simply the mean of the `preds` tensor above compared to `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False,  True])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = (preds == torch.squeeze(y[:4])); correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 0., 1.]), tensor(0.7500))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct.float(), correct.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we calculate the batch_accuracy when there are N columns of activations from the final layer corresponding to the N categories. The basic idea is that, in each row, the model, when trained well, should try and push up the value corresponding to the correct class up higher and the remaining values lower (when using the `cross_entropy` loss function). The index corresponding to the maximum value will then match the correct category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb,yb, mnist=True, print_debug=False):\n",
    "    if mnist:\n",
    "        preds = xb.sigmoid()\n",
    "        correct = (preds>0.5) == yb\n",
    "    else:\n",
    "        acts,preds = torch.max(xb, 1)\n",
    "        yb_squeezed = torch.squeeze(yb)\n",
    "        if print_debug:\n",
    "            print(xb, acts, preds, yb_squeezed)\n",
    "        #print(xb.shape, yb.shape, preds.shape, yb_squeezed.shape)\n",
    "        correct = (preds == yb_squeezed)\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-10.7714,  -4.5953],\n",
      "        [-13.9319,   0.0812],\n",
      "        [ -2.5972,  -5.2215],\n",
      "        [-17.7803,  10.3004]], grad_fn=<AddBackward0>) tensor([-4.5953,  0.0812, -2.5972, 10.3004], grad_fn=<MaxBackward0>) tensor([1, 1, 0, 1]) tensor([1, 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7500)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(acts, y[:4], False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same `validate_epoch` function as we used earlier with `mnist_loss`. The notebook cells below just walk through what `torch.stack` does with the list of batch_accuracy values computed per epoch for each mini-batch in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.7500), tensor(0.2500), tensor(0.3500), tensor(0.8500)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs = [tensor(0.75), tensor(0.25), tensor(0.35), tensor(0.85)]; accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7500, 0.2500, 0.3500, 0.8500])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7500, 0.2500, 0.3500, 0.8500])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, params, mnist=True, print_debug=False):\n",
    "    accs = [batch_accuracy(model(xb, params[0], params[1]), yb, mnist, print_debug) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, lets use mnist_loss and one column of activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5791 0.7846 0.8843 0.9131 0.9292 0.9414 0.9487 0.9531 0.956 0.958 "
     ]
    }
   ],
   "source": [
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)\n",
    "lr = 1.0\n",
    "params = [weights, bias]\n",
    "for i in range(10):\n",
    "    train_epoch(linear1, lr, params, calc_grad_mnist_loss)\n",
    "    print(validate_epoch(linear1, params), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's use cross_entropy_loss and two columns of activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 2]) torch.Size([2])\n",
      "0.5083 0.9048 0.9438 0.9512 0.9555 0.956 0.9585 0.9614 0.9619 0.9624 "
     ]
    }
   ],
   "source": [
    "weights = init_params((28*28,2))\n",
    "bias = init_params(2)\n",
    "lr = 1.0 \n",
    "params = [weights, bias]\n",
    "print(weights.shape, bias.shape)\n",
    "for i in range(10):\n",
    "    train_epoch(linear1, lr, params, calc_grad_ce_loss)\n",
    "    print(validate_epoch(linear1, params, False), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "I am able to use the traditional `cross_entropy_loss` using the negative log-likelihood function to work as expected with the MNIST_SAMPLE dataset of '3's and '7's and two columns of activations from the final layer. In the previous notebook, I could not do so due to my inability to define the `batch_accuracy` function correctly. The key looks to be to use the [`torch.max`](https://pytorch.org/docs/stable/generated/torch.max.html) function to select the column index with the maximum activation value and compare that to `y` (the dependent variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's replace our code with PyTorch/fastai built-in functions and see if we get the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 784]), torch.Size([2]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear2 = nn.Linear(28*28, 2)\n",
    "w,b = linear2.parameters(); w.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets put our step_weights function into a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "        \n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "    \n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BasicOptim(linear2.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets redefine our loss functions to match the template expected by fastai and PyTorch. Lets also redefine the `train_epoch` function to use the optimizer defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad_mnist_loss(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad_ce_loss(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = cross_entropy_loss(preds, yb)\n",
    "    #print(loss)\n",
    "    loss.backward()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, calc_grad_func):\n",
    "    epoch_loss = []\n",
    "    for xb,yb in dl:\n",
    "        epoch_loss.append(calc_grad_func(xb,yb,model))\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    epoch_loss_tnsr = tensor(epoch_loss)\n",
    "    return epoch_loss_tnsr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to redefine the validate_epoch function simply because we don't need to pass the params as args to the built-in Pytorch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch_new(model, mnist=True):\n",
    "    accs = [batch_accuracy(model(xb), yb, mnist) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6663"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch_new(linear2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5787)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(linear2, calc_grad_ce_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs, mnist=True):\n",
    "    for i in range(epochs):\n",
    "        if mnist:\n",
    "            epoch_loss_mean = train_epoch(model, calc_grad_mnist_loss)\n",
    "        else:\n",
    "            epoch_loss_mean = train_epoch(model, calc_grad_ce_loss)\n",
    "        #print(epoch_loss_mean)\n",
    "        print(validate_epoch_new(model, mnist), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.8047 0.8452 0.9126 0.9336 0.9468 0.9551 0.9619 0.9663 0.9668 "
     ]
    }
   ],
   "source": [
    "# mnist_loss\n",
    "lr = 1.\n",
    "linear2 = nn.Linear(28*28,1)\n",
    "#opt = SGD(linear2.parameters(), lr)\n",
    "opt = BasicOptim(linear2.parameters(), lr)\n",
    "train_model(linear2, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5269 0.8877 0.938 0.955 0.9633 0.9643 0.9638 0.9663 0.9658 0.9668 "
     ]
    }
   ],
   "source": [
    "# softmax_loss\n",
    "lr = 1e-2\n",
    "linear3 = nn.Linear(28*28,2)\n",
    "#opt = SGD(linear3.parameters(), lr)\n",
    "opt = BasicOptim(linear3.parameters(), lr)\n",
    "train_model(linear3, 10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple replacement we can make for our BasicOptim optimizer class is to replace it with the built-in SGD optimizer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.4932 0.6807 0.874 0.9204 0.9355 0.9512 0.958 0.9638 0.9658 "
     ]
    }
   ],
   "source": [
    "# mnist_loss\n",
    "lr = 1.\n",
    "linear2 = nn.Linear(28*28,1)\n",
    "opt = SGD(linear2.parameters(), lr)\n",
    "train_model(linear2, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5444 0.8984 0.9399 0.9575 0.9638 0.9648 0.9648 0.9653 0.9658 0.9663 "
     ]
    }
   ],
   "source": [
    "# softmax_loss\n",
    "lr = 1e-2\n",
    "linear3 = nn.Linear(28*28,2)\n",
    "opt = SGD(linear3.parameters(), lr)\n",
    "train_model(linear3, 10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of `train_model`, we can now transition over to using the built-in `Learner.fit` class method. Before we do this, lets redefine batch_accuracy for mnist and softmax separately as there is a need to follow the template here for this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy_mnist(xb,yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy_ce(xb,yb):\n",
    "    _,preds = torch.max(xb, 1)\n",
    "    yb_squeezed = torch.squeeze(yb)\n",
    "    #print(xb.shape, yb.shape, preds.shape, yb_squeezed.shape)\n",
    "    correct = (preds == yb_squeezed)\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_mnist = Learner(dls, nn.Linear(28*28,1), opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_ce = Learner(dls, nn.Linear(28*28,2), opt_func=SGD, loss_func=cross_entropy_loss, metrics=batch_accuracy_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy_mnist</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.636874</td>\n",
       "      <td>0.503316</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.462960</td>\n",
       "      <td>0.232174</td>\n",
       "      <td>0.795388</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.172324</td>\n",
       "      <td>0.162464</td>\n",
       "      <td>0.853778</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.076681</td>\n",
       "      <td>0.099876</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041421</td>\n",
       "      <td>0.074306</td>\n",
       "      <td>0.935721</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>0.949951</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021947</td>\n",
       "      <td>0.051175</td>\n",
       "      <td>0.956820</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019395</td>\n",
       "      <td>0.045197</td>\n",
       "      <td>0.963690</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018082</td>\n",
       "      <td>0.040978</td>\n",
       "      <td>0.966143</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>0.037855</td>\n",
       "      <td>0.968597</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_mnist.fit(10, lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy_ce</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.275928</td>\n",
       "      <td>0.691266</td>\n",
       "      <td>0.508832</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.218829</td>\n",
       "      <td>0.307219</td>\n",
       "      <td>0.883709</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.172936</td>\n",
       "      <td>0.202616</td>\n",
       "      <td>0.936703</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.144097</td>\n",
       "      <td>0.161210</td>\n",
       "      <td>0.954858</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.125797</td>\n",
       "      <td>0.139614</td>\n",
       "      <td>0.963199</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.113691</td>\n",
       "      <td>0.126365</td>\n",
       "      <td>0.965162</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.105253</td>\n",
       "      <td>0.117359</td>\n",
       "      <td>0.966143</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.099056</td>\n",
       "      <td>0.110794</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.094285</td>\n",
       "      <td>0.105764</td>\n",
       "      <td>0.966634</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.090465</td>\n",
       "      <td>0.101761</td>\n",
       "      <td>0.966143</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_ce.fit(10, lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a neural network instead of a linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net_mnist = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1) # 1 column of activations from the final layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net_ce = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,2) # 2 columns of activations from the final layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_mnist = Learner(dls, simple_net_mnist, opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_softmax = Learner(dls, simple_net_ce, opt_func=SGD, loss_func=cross_entropy_loss, metrics=batch_accuracy_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy_mnist</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.361355</td>\n",
       "      <td>0.396705</td>\n",
       "      <td>0.512758</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.163877</td>\n",
       "      <td>0.249748</td>\n",
       "      <td>0.778214</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.088437</td>\n",
       "      <td>0.121506</td>\n",
       "      <td>0.909715</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.056420</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.939647</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041769</td>\n",
       "      <td>0.061811</td>\n",
       "      <td>0.956330</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034433</td>\n",
       "      <td>0.051752</td>\n",
       "      <td>0.963199</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030325</td>\n",
       "      <td>0.045476</td>\n",
       "      <td>0.965162</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027719</td>\n",
       "      <td>0.041226</td>\n",
       "      <td>0.966634</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025876</td>\n",
       "      <td>0.038150</td>\n",
       "      <td>0.969578</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024465</td>\n",
       "      <td>0.035804</td>\n",
       "      <td>0.970559</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023330</td>\n",
       "      <td>0.033946</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022387</td>\n",
       "      <td>0.032427</td>\n",
       "      <td>0.973013</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.021586</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>0.974485</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>0.030063</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020291</td>\n",
       "      <td>0.029114</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>0.028278</td>\n",
       "      <td>0.976448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019280</td>\n",
       "      <td>0.027533</td>\n",
       "      <td>0.976938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>0.026866</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>0.026265</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.018103</td>\n",
       "      <td>0.025718</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_mnist.fit(20, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy_ce</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.085444</td>\n",
       "      <td>0.098483</td>\n",
       "      <td>0.967125</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.083706</td>\n",
       "      <td>0.095735</td>\n",
       "      <td>0.968597</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.081895</td>\n",
       "      <td>0.093388</td>\n",
       "      <td>0.969087</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.080118</td>\n",
       "      <td>0.091353</td>\n",
       "      <td>0.970069</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078438</td>\n",
       "      <td>0.089565</td>\n",
       "      <td>0.970559</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.076881</td>\n",
       "      <td>0.087976</td>\n",
       "      <td>0.971050</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075449</td>\n",
       "      <td>0.086552</td>\n",
       "      <td>0.971050</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.074135</td>\n",
       "      <td>0.085264</td>\n",
       "      <td>0.971050</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072925</td>\n",
       "      <td>0.084091</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071808</td>\n",
       "      <td>0.083017</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070773</td>\n",
       "      <td>0.082028</td>\n",
       "      <td>0.972522</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.069809</td>\n",
       "      <td>0.081112</td>\n",
       "      <td>0.973013</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.068909</td>\n",
       "      <td>0.080260</td>\n",
       "      <td>0.973013</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.068065</td>\n",
       "      <td>0.079465</td>\n",
       "      <td>0.973503</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.067272</td>\n",
       "      <td>0.078721</td>\n",
       "      <td>0.973503</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.066524</td>\n",
       "      <td>0.078021</td>\n",
       "      <td>0.973503</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.065817</td>\n",
       "      <td>0.077362</td>\n",
       "      <td>0.973503</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.065148</td>\n",
       "      <td>0.076739</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.064512</td>\n",
       "      <td>0.076149</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>0.075588</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_ce.fit(20, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretty cool accuracy numbers there! :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
